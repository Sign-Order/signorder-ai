# Sign Order - AI Part

##### 작성/담당: 구수연

이전 PR들 (이전하기 전) : https://github.com/kookmin-sw/capstone-2025-30/pulls?q=is%3Apr+is%3Aclosed+author%3AKooSuYeon

---

## 📋 프로젝트 개요

**AI 파트의 궁극적인 목표**는 **농인 손님과 청인 직원 간의 장벽 없는 소통**을 가능하게 하는 실질적인 변환 모델을 생성하는 것입니다.

### 🔄 핵심 워크플로우

1. **수어 인식**: 매장에 비치된 카메라로 수어 동작을 인식
2. **단어 매칭**: 훈련된 모델로 해당 동작에 일치하는 수어 단어 매칭
3. **문장 변환**: RAG 모델을 통해 매칭된 단어들을 한국어 문장으로 변환
4. **역변환**: 한국어 문장을 한국수어 조합으로 변환

---

## 📁 폴더 구조

| 폴더/파일 | 설명 |
|-----------|------|
| `.github/workflow/deploys.yml` | AWS CI/CD 자동 배포 설정 파일 |
| `certs/` | Self-Signed URL 인증서 |
| `docs/` | 국립 국어원 제공 URL |
| `gesture_dict/` | "카페" 상황에 제한적인 단어 모음 |
| `grpc/` | 문의하기 기능용 AI 서버 및 클라이언트 테스트 파일 |
| `inquiry/` | 데이터셋 전처리 및 Bi-LSTM 모델 생성 파일 |
| `menu/` | 카페스윗 메뉴 DB 연동 및 아바타 URL 관리 |
| `models/` | Bi-LSTM 딥러닝 모델 버전 관리 |
| `nginx/` | 서버 확장을 위한 nginx 설정 |
| `Dockerfile` | AI 서버 실행용 Docker 파일 (데이콘에서 사용 안함) |
| `docker-compose.yaml` | Docker 환경 설정 (데이콘에서 사용 안함) |
| `requirements.txt` | 필요한 라이브러리 집합 |
| `run_*.sh` | 클라이언트 시뮬레이션 실행 스크립트 |

---

## 🛠 기술 스택

- **Deep Learning**: PyTorch, Bi-LSTM
- **NLP**: LangChain, GPT-4o
- **Retrieval**: RAG (BM25 + FAISS)
- **Vision**: MediaPipe
- **Infrastructure**: Docker, nginx, AWS

---

## 🚀 설치 및 실행 방법

### 📋 사전 요구사항

- **Python 버전**: 3.10.10 (필수)
- 사전 공유된 `.env` 파일 및 `certs` 디렉터리

### 🔧 AI 서버 실행

```bash
# 1. 환경 파일 설정
# .env 파일을 최상위 디렉터리에 배치
# certs 디렉터리를 최상위 디렉터리에 배치

# 2. 가상환경 설정
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# 또는 venv\Scripts\activate  # Windows

# 3. 필요한 라이브러리 설치
pip install -r requirements.txt

# 4. AI 서버 실행
sh run_inquiry_server.sh
```

### 🧪 클라이언트 테스트 
(반드시 서버 실행 한 후 테스트를 진행해야 합니다)

```bash
# 기본 설정 (1-4번 동일)

# 한국어 → 한국수어 변환 테스트
sh run_to_ksl.sh

# 한국수어 → 한국어 변환 테스트
sh run_to_korean.sh
```

### ⚙️ 환경 변수 설정

```env
# API 설정
OPENAPI_URL = "http://api.kcisa.kr/openapi/service/rest/meta13/getCTE01701"
OPENAPI_KEY = "YOUR_OPEN_API_KEY"
OPEN_AI_KEY = "YOUR_OPEN_AI_KEY"

# 데이터베이스
MONGO_DB_URL = "YOUR_MONGO_DB_URL"
HF_TOKEN = "YOUR_HUGGING_FACE_TOKEN"

# 서버 설정
AI_EC2_HOST = "AI_SERVER_IP"
AI_EC2_SSH_KEY = "AI_SERVER_SSH_KEY"
AI_TLS_CRT = "AI_SELF_SIGNED_CRT"
AI_TLS_KEY = "AI_SELF_SIGNED_KEY"
```

---

## 🔬 API/모듈 설명

<details>
<summary><strong>🔍 RAG 기반 언어 변환 모델</strong></summary>

### 한국수어문법 기반 RAG 모델

**한국어와 한국수어의 구조적 차이**를 해결하기 위해 RAG(Retrieval-Augmented Generation) 기반 모델을 개발했습니다.

#### 🎯 핵심 특징

- **문법적 맥락 참조**: 한국수어 어순(SOV), 복합어 처리, 위치성 표현 규칙 실시간 참조
- **앙상블 검색기**: BM25 + FAISS 결합으로 키워드 매칭과 의미적 유사성 동시 활용
- **최적화된 가중치**: BM25:FAISS = 0.3:0.7 비율로 의미적 유사성 중심 설정

#### 🔄 양방향 변환 시스템

##### 1️⃣ 한국어 → 한국수어 변환

- **문법 구조 재배열**: 의문문 유형 분기, 복합어 분해, 위치성 처리
- **제약된 출력**: 사전 정의된 수어 단어 집합 내에서만 출력
- **배치 유사도 계산**: 문장 임베딩 기반으로 의미상 유사한 단어 빠른 매칭

```
입력: "커피 한 잔 주세요"
처리: 문법 분석 → 수어 어순 변환 → 단어 매칭
출력: "커피 하나 주다"
```

##### 2️⃣ 한국수어 → 한국어 변환

- **구조 재배열**: 수어 시퀀스를 한국어 어순(SVO)에 맞게 변환
- **문맥 보존**: 비문형적 구성과 생략된 부분 자연스럽게 복원
- **의미 완성**: 복합어 통합 및 은유적 표현 해석

```
입력: "커피 하나 주다"
처리: 문맥 분석 → 어순 재배열 → 자연어 생성
출력: "커피 한 잔 주세요"
```

</details>

<details>
<summary><strong>🧠 Attention Bi-LSTM 딥러닝 모델</strong></summary>

### 동적 손동작 인식을 위한 딥러닝 모델

**실시간 수어 동작 인식**을 위해 Attention 메커니즘이 결합된 양방향 LSTM 모델을 구축했습니다.

#### 🔍 모델 구조

##### 1️⃣ 양방향 LSTM (Bi-LSTM)

**시계열 데이터의 양방향 정보 처리**로 수어 인식 정확도 향상

- **장기 의존 관계 학습**: LSTM의 게이트 구조로 기울기 소실 문제 해결
- **양방향 정보 활용**: 이전·이후 손동작 변화 패턴 동시 고려
- **의미 파악 강화**: 전체 동작 시퀀스를 고려한 정교한 의미 해석

##### 2️⃣ Attention 메커니즘

**중요한 동작에 가중치를 부여**하는 동적 참조 시스템

- **Query-Key-Value 구조**: Decoder가 Encoder의 hidden state를 동적 참조
- **시점별 가중치**: 핵심 움직임 프레임에 집중적 어텐션 적용
- **길이 가변 처리**: 개인차가 있는 수어 속도와 길이에 유연 대응

#### 📊 입력 데이터 구조 (78차원)

| 구성 요소 | 차원 | 설명 |
|-----------|------|------|
| **3D 관절 좌표** | 63차원 | MediaPipe로 추출한 21개 관절의 (x, y, z) 좌표 |
| **관절 간 각도** | 15차원 | 각 손가락별 3개 각도 × 5개 손가락 |

##### 🎯 관절 각도 데이터의 장점

- **개인차 완화**: 손 크기나 카메라 거리 영향 최소화
- **자세 정량화**: 손가락 굽힘 정도의 정밀한 수치 표현
- **안정성 향상**: 외부 환경 변화에 강건한 특징 추출

#### 📈 데이터 증강 기법

**제한된 수어 데이터의 다양성 확장**으로 모델 성능 향상

- **Temporal Jittering**: 프레임 순서 미세 조정으로 시간적 민감도 완화
- **가우시안 노이즈**: 실제 촬영 환경의 흔들림과 센서 오차 모사
- **각도 변화**: ±1~2도 범위의 자연스러운 손가락 움직임 반영
- **Temporal Stretching**: 개인별 동작 속도 차이 대응

#### 📊 성능 향상 결과

| 평가 지표 | 증강 적용 전 | 증강 적용 후 | 개선폭 |
|-----------|--------------|--------------|--------|
| **Top-1 정확도** | 82.3% | **89.7%** | **▲ +7.4%p** |
| **예측 일관성** | 1.6초 | **2.4초** | **▲ +0.8초** |
| **인식 안정성** | 68% | **85%** | **▲ +17%p** |

</details>

---

## 📈 주요 성과

### ✨ 핵심 성능 지표

- **🎯 수어 인식 정확도**: 89.7%
- **⚡ 실시간 처리**: 평균 5초 이내 예측 일관성
- **🔄 양방향 변환**: 한국어 ↔ 한국수어 완전 지원
- **🛡️ 안정성**: 85% 일관된 인식 비율

### 🏆 기술적 혁신

- **문법 기반 RAG**: 한국수어 고유 문법 구조 반영한 변환 시스템
- **멀티모달 융합**: 3D 좌표 + 관절 각도 결합으로 정밀한 동작 인식
- **Attention Bi-LSTM**: 양방향 시계열 학습과 동적 가중치 적용
- **실용적 구현**: 카페 환경에 특화된 실시간 소통 지원

---

## 🤝 Contributing

본 프로젝트는 농인과 청인 간의 소통 장벽 해소를 목표로 하며, 지속적인 개선을 통해 더 나은 접근성을 제공하고자 합니다.

---

## 📧 문의사항

기술적 문의나 협업 제안은 프로젝트 담당자에게 연락해 주세요.